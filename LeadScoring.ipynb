{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaniyaBubere/Lead-Scoring-Model/blob/main/LeadScoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem: Lead Scoring Model\n",
        "\n",
        "Selling something is not an easy task. A business might have many potential customers, commonly referred as leads, but not enough resources to cater them all. Even most of the leads won’t turn into actual bookings. So there is a need for a system that prioritises the leads, and sorts them on the basis of a score, referred to here as lead score. So whenever a new lead is generated, this system analyses the features of the lead and gives it a score that correlates with chances of it being converted into booking. Such ranking of potential customers not only helps in saving time but also helps in increasing the conversion rate by letting the sales team figure out what leads to spend time on.\n",
        "\n",
        "Here you have a dataset of leads with their set of features and their status. You have to build a ML model that predicts the lead score as an OUTPUT on the basis of the INPUT set of features. This lead score will range from 0-100, so more the lead score means more chances of conversion of lead to WON.\n"
      ],
      "metadata": {
        "id": "NFBIAcl7rxkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set:"
      ],
      "metadata": {
        "id": "X6tpyv3asCmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided dataset includes information about leads generated for rental properties. Each row represents a lead and provides various details such as agent ID, lead status, lost reason, budget, lease duration, move-in date, source of lead, destination city and country, desired room type, and lead ID.\n",
        "\n",
        "The dataset also includes information about the source of the leads such as the source website, source city, source country, UTM source, and UTM medium. Finally, each lead has a unique lead ID.\n",
        "\n",
        "LEAD: In the context of sales and marketing, a lead is a potential customer or prospect who has shown interest in a company's products or services.\n",
        "\n",
        "Status: Lead status refers to the current stage of a lead in the sales process. It describes whether a lead is a potential customer, a lost opportunity, or a converted customer.\n",
        "\n",
        "LEASE: Lease refers to a contractual agreement between two parties, whereby the owner of a property (lessor) allows another party (lessee) to use the property for a specified period of time in exchange for rent"
      ],
      "metadata": {
        "id": "ytKVnVxqWc7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement : Develop a machine learning model to predict lead scores ranging from 0-100 based on input features. This will help prioritize leads and improve conversion rates."
      ],
      "metadata": {
        "id": "-78dfYnnuWPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "y9GRTMDsvghI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I imported the necessary libraries and mounted the drive. Then, I inspected the data and checked for duplicate values, and dropped unwanted columns. I performed data cleaning by imputing null values with the mode and changed the values to categories of each column. I used one-hot encoding to represent categorical data.\n",
        "\n",
        "Furthermore, I addressed the issue of unbalanced data using the Synthetic Minority Over-sampling Technique (SMOTE). I implemented two models: Random Forest and XGBoost. I evaluated the performance of the models using metrics such as accuracy, precision, recall, and F1-score, and found that the XGBoost model performed better.\n",
        "\n",
        "In conclusion, I successfully developed a machine learning model to predict lead scores, which can be used to prioritize leads and improve the conversion rates of businesses."
      ],
      "metadata": {
        "id": "hwKSpdW7vihA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "LbG2PfhxseWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "TRwOZo34JpwA"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD4a1GYAJu9Q",
        "outputId": "72633cf5-cbd2-4676-f8e1-b93595234f5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading file \n",
        "df=pd.read_excel(\"/content/drive/MyDrive/Lead Scoring/Data_Science_Internship.xlsx\")"
      ],
      "metadata": {
        "id": "r_kTFqSuJ7zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first look of data set\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mkVzI0KANJCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop first column of dataframe\n",
        "df = df.iloc[: , 1:]"
      ],
      "metadata": {
        "id": "LCLo1Xasm-PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Inspection"
      ],
      "metadata": {
        "id": "51JPbLlNi2xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows and columns\n",
        "rows, columns = df.shape"
      ],
      "metadata": {
        "id": "H3OOcDJffVq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns\n",
        "print(\"Number of rows: \", rows)\n",
        "print(\"Number of columns: \", columns)"
      ],
      "metadata": {
        "id": "IWaD-kojgt5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df[df.duplicated()]"
      ],
      "metadata": {
        "id": "FZHVMntAgz9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the shape after removing duplicates\n",
        "df = df.drop_duplicates(keep = 'first')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Cto79SWMmXyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Pww4ZRxLg7rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have Null Values in our Dataset"
      ],
      "metadata": {
        "id": "GGRdhZR_VpAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describing the data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "MD237hpIg_6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "TlZJuqwmhIS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The leads with STATUS other than ‘WON’ or ‘LOST’ are dropped "
      ],
      "metadata": {
        "id": "S9fe_XCEWGhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for unique value of status column\n",
        "df[\"status\"].unique()"
      ],
      "metadata": {
        "id": "-5odEzQ3MOtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Including only Won and Lost value for status column\n",
        "df = df[df[\"status\"].isin([\"WON\",\"LOST\"])]"
      ],
      "metadata": {
        "id": "d2X8U0ywKJxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing the given value with NA"
      ],
      "metadata": {
        "id": "PzRHKknLhhkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the given value in variable\n",
        "value='9b2d5b4678781e53038e91ea5324530a03f27dc1d0e5f6c9bc9d493a23be9de0' "
      ],
      "metadata": {
        "id": "drk9brXESIRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking for the given value in whole dataset\n",
        "count=df.isin([value]).sum()\n",
        "count"
      ],
      "metadata": {
        "id": "oFYsJ3mkSSj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the given value with a NA value\n",
        "df.replace('9b2d5b4678781e53038e91ea5324530a03f27dc1d0e5f6c9bc9d493a23be9de0', np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "hgNtllbeSag2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking that the value replaced is still present or not \n",
        "count=df.isin([value]).sum()\n",
        "count"
      ],
      "metadata": {
        "id": "HaQ4MGw-TUBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null value\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "IhVcAdxJhwhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Null Percentage of each column\n",
        "round(100*(df.isnull().sum()/len(df.index)), 2)"
      ],
      "metadata": {
        "id": "JQmdLeiSh5Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the columns having more than 40% missing values"
      ],
      "metadata": {
        "id": "pOvfbQ7TlSWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the columns having more than 40% missing values\n",
        "pct_null = df.isnull().sum() / len(df)\n",
        "missing_features = pct_null[pct_null > 0.40].index\n",
        "df.drop(missing_features, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "yW6MURThhxtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the update\n",
        "round(100*(df.isnull().sum()/len(df.index)), 2)"
      ],
      "metadata": {
        "id": "oxj3cv-thxqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 column removed.\n",
        "\n"
      ],
      "metadata": {
        "id": "kI4WToDSlb8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the Rows having  equal or more then 70% missing values"
      ],
      "metadata": {
        "id": "4uT0OiTPXV75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the Rows having  equal or more then 70% missing values\n",
        "pct_null = df.isnull().sum() / len(df)\n",
        "missing_features = pct_null[pct_null >= 0.70].index\n",
        "df.drop(missing_features, axis=0, inplace=True)\n"
      ],
      "metadata": {
        "id": "IM98yaHzld5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "KMCaj37Rld1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Unique Value of DataFrame\n",
        "def get_all_unique_values(df):\n",
        "    for col in df.columns:\n",
        "        print(f\"Unique values in column '{col}':\")\n",
        "        print(df[col].unique())\n",
        "        print()"
      ],
      "metadata": {
        "id": "zqc8JBHhldy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(df)"
      ],
      "metadata": {
        "id": "yJcSg6L4ldws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Missing Data"
      ],
      "metadata": {
        "id": "tmzHIHw9YBrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values by filling them with mode\n",
        "df = df.fillna(df.mode().iloc[0])"
      ],
      "metadata": {
        "id": "fE0BckfSTzsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Null values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "fGpUBG-tYENI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hurreyyy there is no null value in our data set"
      ],
      "metadata": {
        "id": "lLto4pp-YKEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the Values to Category"
      ],
      "metadata": {
        "id": "hVlcq9CGYTJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categories(x, value_counts_dict):\n",
        "  \n",
        "    return 'others' if value_counts_dict[x] < 10 else x\n",
        "\n",
        "# Drop the 'id' column\n",
        "df = df.drop('lead_id', axis=1)\n",
        "\n",
        "# define threshold\n",
        "threshold = 10\n",
        "\n",
        "# get columns with categorical data\n",
        "cat_cols = [col for col in df.select_dtypes(include=['object', 'category']).columns if col != 'status']\n",
        "\n",
        "\n",
        "# loop through categorical columns\n",
        "for col in cat_cols:\n",
        "    print(\"Column Name : \", col)\n",
        "    print(\"-----------------------------------------\")\n",
        "\n",
        "    # # calculate value counts for each category\n",
        "    value_counts_dict = (df[col].value_counts(normalize=True) * 100).to_dict()\n",
        "\n",
        "    # apply change_to_others function to each category\n",
        "    df[col] = df[col].apply(lambda x:categories(x, value_counts_dict))\n",
        "\n",
        "    print(\"After :\")\n",
        "    print(df[col].value_counts(normalize=True) * 100)\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "id": "CLKLfuAMu9Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separating the dependent and independent variables"
      ],
      "metadata": {
        "id": "lCN9paUyYslc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the Lost and Won as 0 and 1 of dependent variable\n",
        "y = df['status'].replace({'LOST': 0, 'WON': 1})"
      ],
      "metadata": {
        "id": "hXy54UBLQt0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  independent variables\n",
        "X=df.drop(columns='status')"
      ],
      "metadata": {
        "id": "DnYjQezaFZV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()\n",
        "X.shape"
      ],
      "metadata": {
        "id": "H_CBrCgAFpJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One Hot Encoding"
      ],
      "metadata": {
        "id": "WeOTqh1M8ZRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing one hot encoding on the dependent variables\n",
        "X=pd.get_dummies(X)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "z3Br_Z2lFwd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "arzd3dISG51W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#converting all columns to int data type\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n"
      ],
      "metadata": {
        "id": "A_O9eDRvPq2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE:"
      ],
      "metadata": {
        "id": "w0aui5ozsvEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#counting dataset\n",
        "df.status.value_counts() "
      ],
      "metadata": {
        "id": "-yPBtO5ynA3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing smote ()\n",
        "smote = SMOTE()\n"
      ],
      "metadata": {
        "id": "SGjKQpIBnA1K"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divivding the dataset into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "mncc6TIws6M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making 2 variable X_train_smote, y_train_smote and fitting \n",
        "X_train_smote, y_train_smote = smote.fit_resample(X,y)\n",
        "# printing the values before and after\n",
        "print(\"Before SMOTE :\" , Counter(y_train))\n",
        "print(\"After SMOTE :\" , Counter(y_train_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huw_mmkdnAxk",
        "outputId": "531c87f3-6272-4ec2-b6bb-771b6499aac9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before SMOTE : Counter({0: 34586, 1: 2459})\n",
            "After SMOTE : Counter({0: 43235, 1: 43235})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for shape of Original dataset shape & Resampled dataset shape\n",
        "print('Original dataset shape', len(df))\n",
        "print('Resampled dataset shape', len(y_train_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMBHh_OYnAvU",
        "outputId": "305322b9-f9e0-4956-beaa-7586c810109f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset shape 46307\n",
            "Resampled dataset shape 86470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making variable for column with each and every columns in dataset\n",
        "columns = list(X.columns)\n",
        "columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTyIPVy1nAsN",
        "outputId": "1d897957-ce13-4159-b66d-2b4702c3e892"
      },
      "execution_count": 45,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['movein',\n",
              " 'Agent_id_2fca346db656187102ce806ac732e06a62df0dbb2829e511a770556d398e1a6e',\n",
              " 'Agent_id_others',\n",
              " 'lost_reason_Low availability',\n",
              " 'lost_reason_Low budget',\n",
              " 'lost_reason_Not interested',\n",
              " 'lost_reason_Not responding',\n",
              " 'lost_reason_others',\n",
              " 'budget_0-0',\n",
              " 'budget_others',\n",
              " 'budget_£121 - £180 Per Week',\n",
              " 'budget_£60 - £120 Per week',\n",
              " 'lease_0',\n",
              " 'lease_Complete Education Year Stay 50 - 52 weeks',\n",
              " 'lease_Full Year Course Stay 40 - 44 weeks',\n",
              " 'lease_others',\n",
              " 'source_7aae3e886e89fc1187a5c47d6cea1c22998ee610ade1f2b7c51be879f0c37ca8',\n",
              " 'source_others',\n",
              " 'source_city_ecc0e7dc084f141b29479058967d0bc07dee25d9690a98ee4e6fdad5168274d7',\n",
              " 'source_city_others',\n",
              " 'source_country_8da82000ef9c4468ba47362a924b895e40662fed846942a1870a674e5c6d1fc2',\n",
              " 'source_country_e09e10e67812e9d236ad900e5d46b4308fc62f5d69446a9750aa698e797e9c96',\n",
              " 'source_country_others',\n",
              " 'utm_source_7f3fa48ca885678134842fa7456f3ece53a97f843b610185d900ac4e467c7490',\n",
              " 'utm_source_bbdefa2950f49882f295b1285d4fa9dec45fc4144bfb07ee6acc68762d12c2e3',\n",
              " 'utm_source_others',\n",
              " 'utm_medium_09076eb7665d1fb9389c7c4517fee0b00e43092eb34821b09b5730c41ebcc50c',\n",
              " 'utm_medium_others',\n",
              " 'des_city_ecc0e7dc084f141b29479058967d0bc07dee25d9690a98ee4e6fdad5168274d7',\n",
              " 'des_city_others',\n",
              " 'des_country_8d23a6e37e0a6431a8f1b43a91026dcff51170a89a6512ff098eaa56a4d5fb19',\n",
              " 'des_country_others']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new Dataframe with balanced data\n",
        "balanced_df = pd.DataFrame(X_train_smote, columns=columns)"
      ],
      "metadata": {
        "id": "su6xK4n-nAkm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing default in y_train_smote \n",
        "balanced_df['status'] = y_train_smote"
      ],
      "metadata": {
        "id": "05X9EM7MnAiU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check shape of new daatframe\n",
        "balanced_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7u1vd8LnAeO",
        "outputId": "1efc8e63-3b3a-4df7-8cf0-fc34a02f2d0f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(86470, 33)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# independent variable (estimator)\n",
        "X = balanced_df.drop(\"status\", axis = 1)\n",
        "\n",
        "# dependent variable (label)\n",
        "y = balanced_df[\"status\"]"
      ],
      "metadata": {
        "id": "uO9evzJvoUsn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divivding the dataset into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "ik4Da0qPHmMa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for Evaluation Metrics"
      ],
      "metadata": {
        "id": "5I4RtGzKtRrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_evaluation_metrics(model, X_train, y_train, X_test, y_test):\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on the training and testing data\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate mean absolute error\n",
        "    MAE_train = mean_absolute_error(y_train, y_pred_train)\n",
        "    print(\"MAE Train :\", MAE_train)\n",
        "\n",
        "    MAE_test = mean_absolute_error(y_test, y_pred_test)\n",
        "    print(\"MAE Test:\", MAE_test)\n",
        "\n",
        "    # Calculate mean squared error\n",
        "    MSE_train = mean_squared_error(y_train, y_pred_train)\n",
        "    print(\"MSE Train :\", MSE_train)\n",
        "\n",
        "    MSE_test = mean_squared_error(y_test, y_pred_test)\n",
        "    print(\"MSE Test:\", MSE_test)\n",
        "\n",
        "    # Calculate root mean squared error\n",
        "    RMSE_train = np.sqrt(MSE_train)\n",
        "    print(\"RMSE Train:\", RMSE_train)\n",
        "\n",
        "    RMSE_test = np.sqrt(MSE_test)\n",
        "    print(\"RMSE Test:\", RMSE_test)\n",
        "\n",
        "    # Calculate RMSPE\n",
        "    sales_mean = np.mean(y_train)\n",
        "    RMSPE_train = RMSE_train / sales_mean\n",
        "    print(\"RMSPE Train:\", RMSPE_train)\n",
        "\n",
        "    RMSPE_test = RMSE_test / sales_mean\n",
        "    print(\"RMSPE Test:\", RMSPE_test)\n",
        "\n",
        "    # Calculate R-squared\n",
        "    R2_train = r2_score(y_train, y_pred_train)\n",
        "    print(\"R2 Train:\", R2_train)\n",
        "\n",
        "    R2_test = r2_score(y_test, y_pred_test)\n",
        "    print(\"R2 Test:\", R2_test)\n",
        "\n",
        "    # Calculate adjusted R-squared\n",
        "    ADJUSTED_R2_train = 1 - ((1 - R2_train) * (168879 - 1) / (168879 - 1 - 26))\n",
        "    print(\"Adjusted R2 Train :\", ADJUSTED_R2_train)\n",
        "\n",
        "    ADJUSTED_R2_test = 1 - ((1 - R2_test) * (168879 - 1) / (168879 - 1 - 26))\n",
        "    print(\"Adjusted R2 Test:\", ADJUSTED_R2_test)\n"
      ],
      "metadata": {
        "id": "C1RsKrZEcg-A"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Model"
      ],
      "metadata": {
        "id": "yN652RFCtXQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()\n",
        "\n",
        "#calling function evaluation_metrics for random forest\n",
        "regression_evaluation_metrics(rf, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2J97RGedshZ",
        "outputId": "7734830c-85f0-448f-fc46-6b8029227ec6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Train : 0.009300537971172498\n",
            "MAE Test: 0.01416058190413284\n",
            "MSE Train : 0.004189330299789019\n",
            "MSE Test: 0.008431592438905147\n",
            "RMSE Train: 0.06472503611268995\n",
            "RMSE Test: 0.0918237030341575\n",
            "RMSPE Train: 0.1294163973214857\n",
            "RMSPE Test: 0.18359963236959503\n",
            "R2 Train: 0.9832426776662545\n",
            "R2 Test: 0.9662735937081127\n",
            "Adjusted R2 Train : 0.9832400973569856\n",
            "Adjusted R2 Test: 0.9662684004823079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating parameter grid  \n",
        "param_grid = {\n",
        "    'max_depth': [10,20,30],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [5, 8, 10],\n",
        "    'n_estimators': [100, 150, 200]\n",
        "}"
      ],
      "metadata": {
        "id": "XQ8FqgLqMMoD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate grid search model\n",
        "random_search = RandomizedSearchCV(estimator = rf,param_distributions= param_grid,  scoring = 'accuracy',  \n",
        "                                   cv = 3, n_jobs = -1, verbose = 1)\n",
        "     "
      ],
      "metadata": {
        "id": "C7_ha15KRrfu"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit grid search to the data\n",
        "random_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "G0BL6FP8Rs88",
        "outputId": "cc78902b-70c9-4d7b-8bf5-509055abb2fe"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "                   param_distributions={'max_depth': [10, 20, 30],\n",
              "                                        'min_samples_leaf': [3, 4, 5],\n",
              "                                        'min_samples_split': [5, 8, 10],\n",
              "                                        'n_estimators': [100, 150, 200]},\n",
              "                   scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [3, 4, 5],\n",
              "                                        &#x27;min_samples_split&#x27;: [5, 8, 10],\n",
              "                                        &#x27;n_estimators&#x27;: [100, 150, 200]},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [3, 4, 5],\n",
              "                                        &#x27;min_samples_split&#x27;: [5, 8, 10],\n",
              "                                        &#x27;n_estimators&#x27;: [100, 150, 200]},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get best parameters\n",
        "random_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJFuFAFRu1P",
        "outputId": "f58e20b8-1905-400b-d8ec-7795aaf6fabc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 100,\n",
              " 'min_samples_split': 8,\n",
              " 'min_samples_leaf': 3,\n",
              " 'max_depth': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get best score\n",
        "random_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzfS9uj3SCJR",
        "outputId": "6233c9aa-e440-496b-8bf5-b2901d4c5314"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calling function evaluation_metrics for random forest\n",
        "regression_evaluation_metrics(random_search, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09gr-9jpSG0b",
        "outputId": "39cdac0e-6255-44f6-fb39-eecd45135d2f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Train : 0.012344432311094217\n",
            "MAE Test: 0.01480792503262996\n",
            "MSE Train : 0.005727585657301699\n",
            "MSE Test: 0.007647172652413111\n",
            "RMSE Train: 0.0756808143276861\n",
            "RMSE Test: 0.08744811405864114\n",
            "RMSPE Train: 0.15132225371945585\n",
            "RMSPE Test: 0.17485073093391218\n",
            "R2 Train: 0.9770896558196006\n",
            "R2 Test: 0.9694112762531744\n",
            "Adjusted R2 Train : 0.9770861280618679\n",
            "Adjusted R2 Test: 0.9694065661708691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XG BOOST"
      ],
      "metadata": {
        "id": "TDhsUFpVp4u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the XGBoost regressor\n",
        "xg_reg = xgb.XGBRegressor()\n",
        "\n",
        "#calling function regression_evaluation_metrics for xgboost\n",
        "regression_evaluation_metrics(xg_reg, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1par6giMSJiq",
        "outputId": "a6754ea3-b887-4451-ce38-4f1c6678c793"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Train : 0.016308002728642253\n",
            "MAE Test: 0.01902612424567739\n",
            "MSE Train : 0.005952953271478674\n",
            "MSE Test: 0.007555525971772775\n",
            "RMSE Train: 0.07715538394356336\n",
            "RMSE Test: 0.08692252856292651\n",
            "RMSPE Train: 0.15427062576755035\n",
            "RMSPE Test: 0.17379983339217286\n",
            "R2 Train: 0.9761881853018567\n",
            "R2 Test: 0.9697778633728644\n",
            "Adjusted R2 Train : 0.9761845187347912\n",
            "Adjusted R2 Test: 0.9697732097380108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Number of trees\n",
        "n_estimators = [50,80,100]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [4,6,8]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# HYperparameter Grid\n",
        "param_dict = {'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}"
      ],
      "metadata": {
        "id": "Zu18pa2ESySE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate grid search model\n",
        "XGboost = RandomizedSearchCV(estimator = xg_reg,param_distributions= param_dict,  scoring = 'accuracy',  \n",
        "                                   cv = 3, n_jobs = -1, verbose = 1)"
      ],
      "metadata": {
        "id": "SF-PFFxTS3mR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function we made evaluation_metrics for XGboost \n",
        "regression_evaluation_metrics(XGboost, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKYhcCW7S52l",
        "outputId": "807e1089-7224-4a1c-b64e-4521025ae333"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:33:38] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
            "\n",
            "MAE Train : 0.012292873928187432\n",
            "MAE Test: 0.01743683799616365\n",
            "MSE Train : 0.004584886250951359\n",
            "MSE Test: 0.008221311847348213\n",
            "RMSE Train: 0.06771178812401397\n",
            "RMSE Test: 0.09067145001238379\n",
            "RMSPE Train: 0.13538834740777497\n",
            "RMSPE Test: 0.18129572581601472\n",
            "R2 Train: 0.9816604537544773\n",
            "R2 Test: 0.9671147169855405\n",
            "Adjusted R2 Train : 0.9816576298127865\n",
            "Adjusted R2 Test: 0.96710965327674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:"
      ],
      "metadata": {
        "id": "MXhcGu8ateFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics, we can see that both Random Forest and XGBoost regressors performed well on the given data.\n",
        "\n",
        "For Random Forest regressor, we can see that the MAE on the training set is 0.0123 and on the test set is 0.0148. Similarly, for XGBoost regressor, we can see that the MAE on the training set is 0.0123 and on the test set is 0.0174.\n",
        "\n",
        "The R2 score for Random Forest regressor on the training set is 0.977 and on the test set is 0.969. Similarly, for XGBoost regressor, the R2 score on the training set is 0.981 and on the test set is 0.967.\n",
        "\n",
        "The Adjusted R2 score for Random Forest regressor on the training set is 0.977 and on the test set is 0.969. Similarly, for XGBoost regressor, the Adjusted R2 score on the training set is 0.982 and on the test set is 0.967."
      ],
      "metadata": {
        "id": "-0uHk8FqtiRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tt seems like the Random Forest model is performing better than the XGBoost model. The Random Forest model has lower MAE, MSE, and RMSE values for both training and testing datasets. Additionally, it has a higher R-squared value for the testing dataset, indicating that it fits the data better"
      ],
      "metadata": {
        "id": "iusM3r8OqbBP"
      }
    }
  ]
}